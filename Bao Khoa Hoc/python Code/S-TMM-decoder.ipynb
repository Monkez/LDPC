{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T02:55:15.075016Z",
     "start_time": "2020-06-04T02:55:14.153348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 3\n",
      "['000' '001' '010' '100' '011' '110' '111' '101']\n",
      "[0 1 2 4 3 6 7 5]\n",
      "[[0 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 1]\n",
      " [1 1 0]\n",
      " [1 1 1]\n",
      " [1 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bootai/miniconda3/envs/de_lai/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_NVVM=/usr/local/cuda-10.1/nvvm/lib64/libnvvm.so.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "/home/bootai/miniconda3/envs/de_lai/lib/python3.6/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_LIBDEVICE=/usr/local/cuda-10.1/nvvm/libdevice.\n",
      "\n",
      "For more information about alternatives visit: ('http://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/local/cuda-10.1/nvvm/libdevice\"\n",
    "os.environ['NUMBAPRO_NVVM'] = \"/usr/local/cuda-10.1/nvvm/lib64/libnvvm.so\"\n",
    "from scipy.special import erfc\n",
    "import time\n",
    "from tqdm.notebook import tnrange\n",
    "import threading\n",
    "import config as cf\n",
    "from numba import jit, njit, vectorize, cuda, int16, float32\n",
    "from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_normal_float32\n",
    "\n",
    "\n",
    "class GF():\n",
    "    def __init__(self, f):\n",
    "        Max = np.max(f)\n",
    "        f2 = np.zeros(Max+1, np.uint8)\n",
    "        f2[f] = 1\n",
    "        f = np.flip(f2)\n",
    "        self.len_of_symbol = Max\n",
    "        self.q = 2**self.len_of_symbol\n",
    "        self.table = np.array(self.make_code_table(f))\n",
    "        \n",
    "    def make_code_table(self, f):\n",
    "        m = len(f)-1\n",
    "        N = 2**m\n",
    "        table = [\"0\"*m]\n",
    "        x =\"\"\n",
    "        for i in range(1,m+1):\n",
    "            if f[i]==0:\n",
    "                x+=\"0\"\n",
    "            else:\n",
    "                x+=\"1\"\n",
    "        for i in range(0, m):\n",
    "            c=\"0\"*m\n",
    "            c = c[0:i] + \"1\"+c[i+1:]\n",
    "            c = c[::-1]\n",
    "            table.append(c)\n",
    "        for i in range(m+1, N):\n",
    "            a = table[-1]\n",
    "            a1 = a[1:]+\"0\"\n",
    "            b = \"0\"*m\n",
    "            if a[0]==\"1\":\n",
    "                b = x\n",
    "            c = self.add_string_code(a1, b)\n",
    "            table.append(c)\n",
    "        return table\n",
    "    \n",
    "    def add_string_code(self, a, b):\n",
    "        c =\"\"\n",
    "        for i in range(self.len_of_symbol):\n",
    "            if a[i]!= b[i] :\n",
    "                c+=\"1\"\n",
    "            else:\n",
    "                c+=\"0\"\n",
    "        return c\n",
    "    \n",
    "    def reserve_e(self, a):\n",
    "            a2 = self.q+1-a\n",
    "            if a2 == self.q:\n",
    "                a2 = 1\n",
    "            if a2 == self.q+1:\n",
    "                a2 = 0\n",
    "            return a2\n",
    "    def add(self, a, b):\n",
    "        if  np.isscalar(a) and  np.isscalar(b):\n",
    "            a= int(a)\n",
    "            b = int(b)\n",
    "            a1 = self.table[a]\n",
    "            b1 = self.table[b]\n",
    "            c1 = self.add_string_code(a1, b1)\n",
    "            c, = np.where(self.table == c1)\n",
    "            return c[0]\n",
    "        elif not np.isscalar(a):\n",
    "            if np.isscalar(b):\n",
    "                raise ValueError(\"a, b must have same shape ( a:\",a.shape,\", b is scalar)\" )\n",
    "            else:\n",
    "                a_size = a.shape\n",
    "                b_size = b.shape\n",
    "                if  len(a_size) ==2 and  len(a_size)==2:\n",
    "                    if a_size[0] != b_size[0] or a_size[1] != b_size[1] :\n",
    "                        raise ValueError(\"a, b must have same shape ( a:\"+ str(a.shape) +\",  b:\"+str(b.shape)+ \")\" )\n",
    "                    else:\n",
    "                        c = np.zeros_like(a, np.uint8)\n",
    "                        for i in range(a_size[0]):\n",
    "                            for j in range(a_size[1]):\n",
    "                                c[i, j] = self.add(a[i, j], b[i, j])\n",
    "                        return c\n",
    "                elif len(a_size)==1 and len(b_size)==1 and a_size ==b_size :\n",
    "                    c = np.zeros_like(a, np.uint8)\n",
    "                    for i in range(a_size[0]):\n",
    "                        c[i] = self.add(a[i], b[i])\n",
    "                    return c\n",
    "                else:\n",
    "                    raise ValueError(\"a, b must have same shape ( a:\"+ str(a.shape) +\",  b:\"+str(b.shape)+ \")\" )         \n",
    "    def multi(self, a, b):\n",
    "        if  np.isscalar(a) and  np.isscalar(b):\n",
    "                if a ==0 or b == 0:\n",
    "                    return 0\n",
    "                else:\n",
    "                    c = (a+b-2) % (self.q-1)\n",
    "                    return c+1\n",
    "        elif not np.isscalar(a):\n",
    "            a_size = a.shape\n",
    "            if np.isscalar(b):\n",
    "                c = [self.multi(i, b) for i in a]\n",
    "                return np.array(c)\n",
    "            b_size = b.shape\n",
    "            if a_size[1] != b_size[0] :\n",
    "                raise ValueError(\"Can not multiply 2 matrix of dimension: \", a.shape, b.shape)\n",
    "            else:\n",
    "                c = np.zeros((a_size[0], b_size[1]), np.uint8)\n",
    "                for i in range(a_size[0]):\n",
    "                    for j in range(b_size[1]):\n",
    "                        for k in range(a_size[1]):\n",
    "                            c[i, j] =self.add(c[i, j], self.multi(a[i, k], b[k, j])) \n",
    "                return c\n",
    "\n",
    "gl = GF([3,  1, 0])\n",
    "q = gl.q\n",
    "table_str = gl.table.copy()\n",
    "table = [int(i, 2) for i in table_str]\n",
    "table = np.array(table)\n",
    "len_of_symbol = gl.len_of_symbol\n",
    "n = 35\n",
    "Scale = 50\n",
    "dc = 5\n",
    "q = 8\n",
    "M = int(np.log2(q))\n",
    "print(\"M:\", M)\n",
    "dtype = np.int16\n",
    "#dtype = np.float32\n",
    "G = np.load(\"G.npy\").astype(np.int16)\n",
    "H = np.load(\"H.npy\").astype(np.int16)\n",
    "m = H.shape[0]\n",
    "n = H.shape[1]\n",
    "k = n- m\n",
    "H_non_zeros_index  = np.zeros((m, dc), np.uint16)\n",
    "for i in range(m):\n",
    "    stt = 0\n",
    "    for j in range(n):\n",
    "        if H[i, j]!=0:\n",
    "            H_non_zeros_index[i, stt] = j\n",
    "            stt+=1  \n",
    "Hmn = np.zeros((m, dc), np.int16)  \n",
    "for i in range(m):\n",
    "    Hmn[i]= H[i][H_non_zeros_index[i]]\n",
    "#print(Hmn)       \n",
    "\n",
    "U_Hmn = np.zeros_like(Hmn)\n",
    "for i in range(m):\n",
    "    for j in range(dc):\n",
    "        U_Hmn[i, j] = gl.reserve_e(Hmn[i, j])\n",
    "#print(U_Hmn)\n",
    "print(table_str)\n",
    "print(table)\n",
    "table_bits = np.array([np.array(list(i)).astype(np.int16) for i in table_str])\n",
    "print(table_bits)\n",
    "table_bits = cuda.to_device(table_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T02:55:15.430300Z",
     "start_time": "2020-06-04T02:55:15.355271Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def add_1d(a, b, c, table):\n",
    "    for i in range(a.shape[0]):\n",
    "        c[i]=table[a[i]]^table[b[i]]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def add_1d_scalar(a, b, c, table):\n",
    "    for i in range(a.shape[0]):\n",
    "        c[i]=table[a[i]]^table[b]\n",
    "        for j in range(q):\n",
    "            if c[i]==table[j]:\n",
    "                c[i]=j\n",
    "                break\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def multi_1d_scalar(a, b, c):\n",
    "    for i in range(a.shape[0]):\n",
    "        if a[i]==0 and b ==0:\n",
    "            c[i]=1\n",
    "        else:\n",
    "            c[i]=(a[i]+b-2) % (q-1)+1\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def sub_Q_permutation(sub_Q, Hmn, fix_arr0, sub_Q_permuted):\n",
    "    fix_arr =cuda.local.array(shape=(5, 7),dtype=int16)\n",
    "    for i in range(dc):\n",
    "        multi_1d_scalar(fix_arr0, Hmn[i], fix_arr[i])\n",
    "        sub_Q_permuted[0, i]=sub_Q[0, i]\n",
    "        for j in range(q-1):\n",
    "            sub_Q_permuted[fix_arr[i][j], i] = sub_Q[j+1, i]\n",
    "\n",
    "            \n",
    "@cuda.jit(device=True)\n",
    "def sub_Q_selection(Q, H_index, sub_Q):\n",
    "    for  x in range(sub_Q.shape[0]):\n",
    "        for y in range(sub_Q.shape[1]):\n",
    "            sub_Q[x, y] = Q[x, H_index[y]]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def Zn(sub_Q, zn):\n",
    "    min_arr = cuda.local.array(shape=(5),dtype=int16)\n",
    "    for i in range(dc):\n",
    "        min_arr[i] = sub_Q[0, i]\n",
    "        zn[i]=0\n",
    "        for j in range(q):\n",
    "            if min_arr[i]> sub_Q[j, i]:\n",
    "                min_arr[i]=sub_Q[j, i]\n",
    "                zn[i]=j\n",
    "                \n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def get_code(sub_Q, zn):\n",
    "    min_arr = cuda.local.array(shape=(35),dtype=int16)\n",
    "    for i in range(35):\n",
    "        min_arr[i] = sub_Q[0, i]\n",
    "        zn[i]=0\n",
    "        for j in range(q):\n",
    "            if min_arr[i]> sub_Q[j, i]:\n",
    "                min_arr[i]=sub_Q[j, i]\n",
    "                zn[i]=j\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def Delta_conversation(sub_Q, zn, fix_arr0, table, sub_Q_Delta):\n",
    "    fix_arr =cuda.local.array(shape=(5, 8),dtype=int16)\n",
    "    for i in range(dc):\n",
    "        add_1d_scalar(fix_arr0, zn[i], fix_arr[i], table)\n",
    "        for j in range(q):\n",
    "            sub_Q_Delta[fix_arr[i][j], i] = sub_Q[j, i]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def Bta(zn, B, table):\n",
    "    B[0] = zn[0]\n",
    "    for i in range(zn.shape[0]-1):\n",
    "        add_1d_scalar(B[i], zn[i+1], B[i+1], table)\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def tree_finder_1row(A, M):\n",
    "    cols = cuda.local.array(shape=(2),dtype=int16)\n",
    "    values = cuda.local.array(shape=(2),dtype=int16)\n",
    "    if A[0]<=A[1]:\n",
    "        cols[0]=0\n",
    "        cols[1]=1\n",
    "        values[0]=A[0]\n",
    "        values[1]=A[1]\n",
    "    else:\n",
    "        cols[0]=1\n",
    "        cols[1]=0\n",
    "        values[0]=A[1]\n",
    "        values[1]=A[0]\n",
    "\n",
    "    for i in range(2, dc):\n",
    "        if A[i]<values[0]:\n",
    "            values[1]=values[0]\n",
    "            cols[1]=cols[0]\n",
    "            values[0]=A[i]\n",
    "            cols[0]=i\n",
    "        elif A[i]>=values[0] and A[i]<values[1]:\n",
    "            values[1]=A[i]\n",
    "            cols[1]=i\n",
    "    \n",
    "    M[0]= values[0]\n",
    "    M[1] = values[1]\n",
    "    M[2]=cols[0]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def tree_finder(A, M):\n",
    "    M[0][0]= 0\n",
    "    M[0][1]=0\n",
    "    M[0][2]=0\n",
    "    for i in range(1, q):\n",
    "        tree_finder_1row(A[i], M[i])\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def trellis_building(M, config, trellis):\n",
    "    for i in range(q):\n",
    "        trellis[i, 0] = M[i, 0]\n",
    "    for i in range(1, q):\n",
    "        for j in range(1, 1+(q-1)//2):\n",
    "            if M[config[i, j-1, 0]][2]!=M[config[i, j-1, 1]][2]:\n",
    "                trellis[i, j] = max(M[config[i, j-1, 0]][0], M[config[i, j-1, 1]][0])\n",
    "            else:\n",
    "                trellis[i, j]=10000\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def min_finder(A, min_out):\n",
    "    min_out[0]=A[0]\n",
    "    min_out[1]=0\n",
    "    for i in range(1, A.shape[0]):\n",
    "        if min_out[0]>A[i]:\n",
    "            min_out[0]=A[i]\n",
    "            min_out[1]=i\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def extra_column(trellis, M, config, extra_col):\n",
    "    for i in range(q):\n",
    "        min_out = cuda.local.array(shape=(2),dtype=int16)\n",
    "        min_finder(trellis[i], min_out)\n",
    "        extra_col[i, 0]=min_out[0]\n",
    "        extra_col[i, 1]= M[i, 0]\n",
    "        extra_col[i, 2]= M[i, 1]\n",
    "        extra_col[i, 5]= M[i, 2]\n",
    "        if i >0:\n",
    "            if min_out[1]==0:\n",
    "                extra_col[i, 3]=extra_col[i, 4]=M[i][2]\n",
    "            else:\n",
    "                extra_col[i, 3] = M[config[i, min_out[1]-1, 0]][2]\n",
    "                extra_col[i, 4] = M[config[i, min_out[1]-1, 1]][2]\n",
    "\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def dR_computing(extra_column, dR):\n",
    "    for i in range(q):\n",
    "        for j in range(dc):\n",
    "            if extra_column[i][3]==j or extra_column[i][4]==j:\n",
    "                if extra_column[i][3]==extra_column[i][4]:\n",
    "                    dR[i, j]=extra_column[i][2]\n",
    "                else:\n",
    "                    if extra_column[i][5]== j:\n",
    "                        dR[i, j]=extra_column[i][2]\n",
    "                    else:\n",
    "                        dR[i, j]=extra_column[i][1]\n",
    "            else:\n",
    "                dR[i, j]=extra_column[i][0]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def R_computing(dR, B, zn, R, table):\n",
    "    for i in range(q):\n",
    "        for j in range(dc):\n",
    "            index = cuda.local.array(shape=(1),dtype=int16)\n",
    "            index[0]= table[i]^table[B]^table[zn[j]]\n",
    "            for l in range(q):\n",
    "                if index[0] == table[l]:\n",
    "                    index[0]=l\n",
    "                    break\n",
    "            R[index, j]=dR[i, j]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def CN(sub_Q_permuted, zn, fix_arr0, table, config, R):\n",
    "    sub_Q_Delta = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    Delta_conversation(sub_Q_permuted, zn, fix_arr0, table, sub_Q_Delta)    \n",
    "    B = cuda.local.array(shape=(dc, 1),dtype=int16)\n",
    "    Bta(zn, B, table)\n",
    "    #B=B[-1][0]\n",
    "    M = cuda.local.array(shape=(q, 3),dtype=int16)\n",
    "    tree_finder(sub_Q_Delta, M)\n",
    "    trellis = cuda.local.array(shape=(8, 4),dtype=int16)\n",
    "    trellis_building(M, config, trellis)\n",
    "    extra_columm = cuda.local.array(shape=(q, 6),dtype=int16)\n",
    "    extra_column(trellis, M, config, extra_columm)\n",
    "    dR = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    dR_computing(extra_columm, dR)\n",
    "    R_computing(dR, B[-1][0], zn, R, table)\n",
    "\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def update_sub_Q(sub_Q_permuted, R, sub_Q_updated):\n",
    "    for i in range(R.shape[0]):\n",
    "        for j in range(R.shape[1]):\n",
    "            sub_Q_updated[i][j] =  sub_Q_permuted[i][j]+R[i][j]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def subtract(Q1, Q2, Q3):\n",
    "    for i in range(Q1.shape[0]):\n",
    "        for j in range(Q1.shape[1]):\n",
    "            Q3[i][j] =  Q1[i][j]- Q2[i][j]\n",
    "\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def update_Q(Q, sub_Q_updated, H_index):\n",
    "    for i in range(Q.shape[0]):\n",
    "        for j in range(Q.shape[1]):\n",
    "            for y in range(dc):\n",
    "                if j == H_index[y]:\n",
    "                    Q[i, j]=sub_Q_updated[i, y]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def debug(X, Y):\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            Y[i, j] =X[i, j]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def Normal(sub_Q, zn, sub_Q_normaled):\n",
    "    for i in range(sub_Q.shape[0]):\n",
    "        for j in range(sub_Q.shape[1]):\n",
    "            sub_Q_normaled[i][j] =  sub_Q[i, j]-sub_Q[zn[j], j]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def Normal2(sub_Q):\n",
    "    for i in range(sub_Q.shape[0]):\n",
    "        for j in range(sub_Q.shape[1]):\n",
    "            if sub_Q[i, j]>10000:\n",
    "                sub_Q[i, j]=10000\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def errors_computing(code_out, errors):\n",
    "    for i in range(code_out.shape[0]):\n",
    "        errors[i]=0\n",
    "        for j in range(n):\n",
    "            if code_out[i][j]!=0:\n",
    "                errors[i]+=1\n",
    "\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def quick_check(code, out):\n",
    "    out[0]=0\n",
    "    for i in range(code.shape[0]):\n",
    "        out[0]+=code[i]   \n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def Decoder(Q, Hmn, U_Hmn, H_non_zeros_index, fix_arr0, fix_arr1, table, config, code_out):\n",
    "    Rmna = cuda.local.array(shape=(m, q, dc),dtype=int16)\n",
    "    for i in range(m):\n",
    "        for j in range(q):\n",
    "            for k in range(dc):\n",
    "                Rmna[i][j][k]=0\n",
    "    sub_Q = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    sub_Q_permuted = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "\n",
    "    R = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    sub_Q_updated = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    sub_Q_unpermuted = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    zn = cuda.local.array(shape=(dc),dtype=int16)\n",
    "    sub_Q_normaled = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    check_value = cuda.local.array(shape=(1),dtype=int16)\n",
    "    \n",
    "    for _iter in range(10):\n",
    "        for i in range(m):\n",
    "            sub_Q_selection(Q, H_non_zeros_index[i], sub_Q)\n",
    "            sub_Q_permutation(sub_Q, Hmn[i], fix_arr1, sub_Q_permuted)\n",
    "            subtract(sub_Q_permuted, Rmna[i],  sub_Q_permuted)\n",
    "            Zn(sub_Q_permuted, zn)\n",
    "            Normal(sub_Q_permuted, zn, sub_Q_normaled)\n",
    "            CN(sub_Q_normaled, zn, fix_arr0, table, config, R)\n",
    "            debug(R, Rmna[i])\n",
    "            update_sub_Q(sub_Q_normaled, R, sub_Q_updated)\n",
    "            #Normal2(sub_Q_updated)\n",
    "            sub_Q_permutation(sub_Q_updated, U_Hmn[i], fix_arr1, sub_Q_unpermuted)\n",
    "            update_Q(Q, sub_Q_unpermuted, H_non_zeros_index[i])\n",
    "        get_code(Q, code_out)\n",
    "        quick_check(code_out, check_value)\n",
    "        if check_value[0]==0:\n",
    "            break\n",
    "\n",
    "@cuda.jit\n",
    "def multi_Decoder(Q, Hmn, U_Hmn, H_non_zeros_index, fix_arr0, fix_arr1, table, config, code_out, errors):\n",
    "    i = cuda.grid(1)\n",
    "    Decoder(Q[i], Hmn, U_Hmn, H_non_zeros_index, fix_arr0, fix_arr1, table, config, code_out[i])\n",
    "    errors_computing(code_out, errors)\n",
    "    \n",
    "lop10e = np.log10(np.e)\n",
    "@cuda.jit\n",
    "def log10(A, B, C):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < A.shape[0] and j < A.shape[1]:\n",
    "        B[i][j]= lop10e*math.log(A[i][j])\n",
    "        if B[i][j]>3:\n",
    "            B[i][j]=3\n",
    "        C[j][i] = int(B[i][j]*100)\n",
    "\n",
    "@cuda.jit\n",
    "def probBits(bits, probBs, N0):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i <bits.shape[0] and j < bits.shape[1]:\n",
    "        d1 = abs(-1-bits[i][j])\n",
    "        d2 = abs(1-bits[i][j])\n",
    "        p0 = np.e**(-d1/N0)/(np.e**(-d1/N0)+np.e**(-d2/N0))\n",
    "        p1 = 1-p0\n",
    "        probBs[i][j][0] = p0\n",
    "        probBs[i][j][1] = p1\n",
    "\n",
    "@cuda.jit\n",
    "def probS(probBs, table_bits, Q_out):\n",
    "    i = cuda.grid(1)\n",
    "    if i <probBs.shape[0]:\n",
    "        p_max = 0\n",
    "        for j in range(q):\n",
    "            Q_out[i][j]=1\n",
    "            for k in range(M):\n",
    "                Q_out[i][j]*=probBs[i][k][table_bits[j][k]]\n",
    "            if Q_out[i][j] >  p_max:\n",
    "                p_max = Q_out[i][j]\n",
    "        for j in range(q):\n",
    "            Q_out[i][j] = p_max/Q_out[i][j]\n",
    "        \n",
    "\n",
    "@cuda.jit\n",
    "def S2B(message, table_bits, bits_out):\n",
    "    for i in range(message.shape[0]):\n",
    "        for j in range(M):\n",
    "            bits_out[i, j]= table_bits[message[i]][j]\n",
    "\n",
    "@cuda.jit\n",
    "def rand_array(rng_states, N0, out):\n",
    "    thread_id = cuda.grid(1)\n",
    "    x = xoroshiro128p_normal_float32(rng_states, thread_id)\n",
    "    out[thread_id] = x\n",
    "    out[thread_id] = out[thread_id]*N0\n",
    "    out[thread_id] = out[thread_id]-1\n",
    "    \n",
    "@cuda.jit\n",
    "def hsplit(A, B):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i<A.shape[0] and j < A.shape[1]:\n",
    "        B[j//n][i][j%n]=A[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T02:55:17.496690Z",
     "start_time": "2020-06-04T02:55:16.588404Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "config = cuda.to_device(np.load(\"config.npy\"))\n",
    "fix_arr0 = cuda.to_device(np.arange(q))\n",
    "fix_arr1 = cuda.to_device(np.arange(q))[1:]\n",
    "U_Hmn = cuda.to_device(U_Hmn)\n",
    "Hmn = cuda.to_device(Hmn)\n",
    "H_non_zeros_index = cuda.to_device(H_non_zeros_index)\n",
    "table = cuda.to_device(table)\n",
    "zn = cuda.to_device(np.zeros(dc, np.int16))\n",
    "code_out = cuda.to_device(np.zeros((batch_size, n), np.int16))\n",
    "errors = np.zeros(batch_size, np.int16)\n",
    "threads_per_block_rd = 128\n",
    "blocks_rd = (n*M*batch_size+threads_per_block_rd-1)//threads_per_block_rd\n",
    "rng_states = create_xoroshiro128p_states(threads_per_block_rd * blocks_rd, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T02:55:18.804986Z",
     "start_time": "2020-06-04T02:55:18.779371Z"
    }
   },
   "outputs": [],
   "source": [
    "cf.A0 = cuda.to_device(np.zeros((batch_size*M*n), dtype=np.float32))\n",
    "cf.A = cuda.to_device(np.zeros((batch_size*n , M), dtype=np.float32))\n",
    "cf.B = cuda.to_device(np.zeros((batch_size*n, 3, 2)))\n",
    "cf.C = cuda.to_device(np.zeros((batch_size*n, q)))\n",
    "cf.C2 = cuda.to_device(np.zeros((batch_size*n, q)))\n",
    "cf.C3 = cuda.to_device(np.zeros((q, batch_size*n), np.int16))\n",
    "cf.out = cuda.to_device(np.zeros((batch_size, q, n), np.int16))\n",
    "def BPSK(sample, SNRdB):\n",
    "    Eb = 1\n",
    "    N0 = Eb/10**(SNRdB/10)\n",
    "    sigma = np.sqrt(N0/2)\n",
    "    #print(N0, sigma)\n",
    "    rand_array[blocks_rd, threads_per_block_rd](rng_states, sigma, cf.A0)\n",
    "    cf.A = cf.A0.reshape((batch_size*n, M))\n",
    "    thread_probBits = (128, 8)\n",
    "    block_probBits = ((cf.A.shape[0]+thread_probBits[0]-1)//thread_probBits[0], (cf.A.shape[1]+thread_probBits[1]-1)//thread_probBits[1])\n",
    "    probBits[block_probBits, thread_probBits](cf.A, cf.B, 1)\n",
    "    thread_probS = 128\n",
    "    block_probS = (cf.B.shape[0]+thread_probS-1)//thread_probS\n",
    "    probS[block_probS, thread_probS](cf.B, table_bits, cf.C)\n",
    "    thread_log10 = (128, 8)\n",
    "    block_log10 = ((cf.C.shape[0]+thread_log10[0]-1)//thread_log10[0], (cf.C.shape[1]+thread_log10[1]-1)//thread_log10[1])\n",
    "    log10[thread_log10, block_log10](cf.C, cf.C2, cf.C3)\n",
    "    thread_hsplit = (8, 128)\n",
    "    block_hsplit = ((cf.C3.shape[0]+thread_hsplit[0]-1)//thread_hsplit[0], (cf.C3.shape[1]+thread_hsplit[1]-1)//thread_hsplit[1])\n",
    "    hsplit[block_hsplit, thread_hsplit](cf.C3, cf.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T02:55:19.921847Z",
     "start_time": "2020-06-04T02:55:19.913274Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(SNRdB, samples, batch_size):\n",
    "    step= samples// batch_size\n",
    "    eb = 0\n",
    "    ef = 0\n",
    "    for i in tnrange(step):\n",
    "        BPSK(batch_size, SNRdB)\n",
    "        multi_Decoder[4, batch_size//4](cf.out, Hmn, U_Hmn, H_non_zeros_index, fix_arr0, fix_arr1, table, config, code_out, errors) \n",
    "        eb+=np.sum(errors)\n",
    "        for i in range(batch_size):\n",
    "            if errors[i]!=0:\n",
    "                ef+=1\n",
    "    print(SNRdB, step*batch_size, ef, eb, np.log10(ef/ (step*batch_size)), np.log10(eb/ (step*batch_size*35)))\n",
    "    return step*batch_size, ef, eb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T02:55:49.253734Z",
     "start_time": "2020-06-04T02:55:21.039991Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf8570bc08541e8988270599b3f235c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 3072 755 5092 -0.6094742597302861 -1.3246008607281323\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70766ddb410b4504baf0a7b60265b983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 7168 383 2054 -1.272199222685446 -2.086865601743085\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2927f092be4e1fb776377e95136d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2 31744 189 809 -2.2251998463008404 -3.137781173212088\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68f9d781cb44051978619f2d21fb0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=488.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-01f0668fcb13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSNRdB_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSNRdB_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSamples_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mef_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-8af66e0f52a0>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(SNRdB, samples, batch_size)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtnrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mBPSK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSNRdB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmulti_Decoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHmn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU_Hmn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_non_zeros_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_arr0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_arr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0meb\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/de_lai/lib/python3.6/site-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgriddim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblockdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msharedmem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m         \u001b[0mcfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mspecialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/de_lai/lib/python3.6/site-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m                           \u001b[0mblockdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblockdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m                           \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m                           sharedmem=self.sharedmem)\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/de_lai/lib/python3.6/site-packages/numba/cuda/compiler.py\u001b[0m in \u001b[0;36m_kernel_call\u001b[0;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;31m# retrieve auto converted arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mwb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mretr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0mwb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernelargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/de_lai/lib/python3.6/site-packages/numba/cuda/args.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m             stream=stream)\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mretr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_to_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdevary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/de_lai/lib/python3.6/site-packages/numba/cuda/cudadrv/devices.py\u001b[0m in \u001b[0;36m_require_cuda_context\u001b[0;34m(*args, **kws)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_require_cuda_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_require_cuda_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/de_lai/lib/python3.6/site-packages/numba/cuda/cudadrv/devicearray.py\u001b[0m in \u001b[0;36mcopy_to_host\u001b[0;34m(self, ary, stream)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malloc_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0m_driver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_to_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhostary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malloc_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mary\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/de_lai/lib/python3.6/site-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36mdevice_to_host\u001b[0;34m(dst, src, size, stream)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuMemcpyDtoH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m     \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost_pointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_pointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mvarargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/de_lai/lib/python3.6/site-packages/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36msafe_cuda_api_call\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'call driver api: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SNRdB_arr = (0,  1, 2, 3, 4, 4.5, 5, 5.4, 5.6, 5.8, 6)\n",
    "Samples_arr= (4000, 8000, 32000, 500000, 2000000, 8000000, 20000000, 40000000, 60000000, 100000000)\n",
    "ef_arr = []\n",
    "es_arr = []\n",
    "S = []\n",
    "for i in range(len(SNRdB_arr)):\n",
    "    s, ef, es = test(SNRdB_arr[i], Samples_arr[i], batch_size)\n",
    "    S.append(s)\n",
    "    ef_arr.append(ef)\n",
    "    es_arr.append(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T01:34:15.100259Z",
     "start_time": "2020-06-04T01:34:14.301395Z"
    }
   },
   "outputs": [],
   "source": [
    "N = len(S)\n",
    "SER = [es_arr[i]/(S[i]*35) for i in range(N)]\n",
    "FER = [ef_arr[i]/(S[i]) for i in range(N)]\n",
    "import  matplotlib.pyplot as plt \n",
    "fig = plt.figure(figsize=(7,6))\n",
    "# plt.plot(SNRdB1, BER_BPSK, label='B-PSK', linewidth=4.0)\n",
    "plt.plot(SNRdB_arr[:N], SER,'-', label='SER-LDPC-GF(8)-Iter-10', linewidth=4.0)\n",
    "plt.plot(SNRdB_arr[:N], FER,'-', label='FER-LDPC-GF(8)-Iter-10', linewidth=4.0)\n",
    "plt.xticks(np.arange(0, 8, 1))\n",
    "plt.yscale('log')\n",
    "plt.ylabel('log10')\n",
    "plt.xlabel('SNR(dB)')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "# plt.savefig('Ber.png')\n",
    "# plt.close(fig)  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_de_lai)",
   "language": "python",
   "name": "conda_de_lai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
