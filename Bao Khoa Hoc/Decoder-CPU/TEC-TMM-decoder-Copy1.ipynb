{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T06:45:06.786504Z",
     "start_time": "2020-07-08T06:45:05.840386Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/local/cuda-10.1/nvvm/libdevice\"\n",
    "os.environ['NUMBAPRO_NVVM'] = \"/usr/local/cuda-10.1/nvvm/lib64/libnvvm.so\"\n",
    "from scipy.special import erfc\n",
    "import time\n",
    "from tqdm.notebook import tnrange\n",
    "import threading\n",
    "import config as cf\n",
    "from numba import jit, njit, vectorize, cuda, int16, float32\n",
    "from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_normal_float32\n",
    "\n",
    "\n",
    "class GF():\n",
    "    def __init__(self, f):\n",
    "        Max = np.max(f)\n",
    "        f2 = np.zeros(Max+1, np.uint8)\n",
    "        f2[f] = 1\n",
    "        f = np.flip(f2)\n",
    "        self.len_of_symbol = Max\n",
    "        self.q = 2**self.len_of_symbol\n",
    "        self.table = np.array(self.make_code_table(f))\n",
    "        \n",
    "    def make_code_table(self, f):\n",
    "        m = len(f)-1\n",
    "        N = 2**m\n",
    "        table = [\"0\"*m]\n",
    "        x =\"\"\n",
    "        for i in range(1,m+1):\n",
    "            if f[i]==0:\n",
    "                x+=\"0\"\n",
    "            else:\n",
    "                x+=\"1\"\n",
    "        for i in range(0, m):\n",
    "            c=\"0\"*m\n",
    "            c = c[0:i] + \"1\"+c[i+1:]\n",
    "            c = c[::-1]\n",
    "            table.append(c)\n",
    "        for i in range(m+1, N):\n",
    "            a = table[-1]\n",
    "            a1 = a[1:]+\"0\"\n",
    "            b = \"0\"*m\n",
    "            if a[0]==\"1\":\n",
    "                b = x\n",
    "            c = self.add_string_code(a1, b)\n",
    "            table.append(c)\n",
    "        return table\n",
    "    \n",
    "    def add_string_code(self, a, b):\n",
    "        c =\"\"\n",
    "        for i in range(self.len_of_symbol):\n",
    "            if a[i]!= b[i] :\n",
    "                c+=\"1\"\n",
    "            else:\n",
    "                c+=\"0\"\n",
    "        return c\n",
    "    \n",
    "    def reserve_e(self, a):\n",
    "            a2 = self.q+1-a\n",
    "            if a2 == self.q:\n",
    "                a2 = 1\n",
    "            if a2 == self.q+1:\n",
    "                a2 = 0\n",
    "            return a2\n",
    "    def add(self, a, b):\n",
    "        if  np.isscalar(a) and  np.isscalar(b):\n",
    "            a= int(a)\n",
    "            b = int(b)\n",
    "            a1 = self.table[a]\n",
    "            b1 = self.table[b]\n",
    "            c1 = self.add_string_code(a1, b1)\n",
    "            c, = np.where(self.table == c1)\n",
    "            return c[0]\n",
    "        elif not np.isscalar(a):\n",
    "            if np.isscalar(b):\n",
    "                raise ValueError(\"a, b must have same shape ( a:\",a.shape,\", b is scalar)\" )\n",
    "            else:\n",
    "                a_size = a.shape\n",
    "                b_size = b.shape\n",
    "                if  len(a_size) ==2 and  len(a_size)==2:\n",
    "                    if a_size[0] != b_size[0] or a_size[1] != b_size[1] :\n",
    "                        raise ValueError(\"a, b must have same shape ( a:\"+ str(a.shape) +\",  b:\"+str(b.shape)+ \")\" )\n",
    "                    else:\n",
    "                        c = np.zeros_like(a, np.uint8)\n",
    "                        for i in range(a_size[0]):\n",
    "                            for j in range(a_size[1]):\n",
    "                                c[i, j] = self.add(a[i, j], b[i, j])\n",
    "                        return c\n",
    "                elif len(a_size)==1 and len(b_size)==1 and a_size ==b_size :\n",
    "                    c = np.zeros_like(a, np.uint8)\n",
    "                    for i in range(a_size[0]):\n",
    "                        c[i] = self.add(a[i], b[i])\n",
    "                    return c\n",
    "                else:\n",
    "                    raise ValueError(\"a, b must have same shape ( a:\"+ str(a.shape) +\",  b:\"+str(b.shape)+ \")\" )         \n",
    "    def multi(self, a, b):\n",
    "        if  np.isscalar(a) and  np.isscalar(b):\n",
    "                if a ==0 or b == 0:\n",
    "                    return 0\n",
    "                else:\n",
    "                    c = (a+b-2) % (self.q-1)\n",
    "                    return c+1\n",
    "        elif not np.isscalar(a):\n",
    "            a_size = a.shape\n",
    "            if np.isscalar(b):\n",
    "                c = [self.multi(i, b) for i in a]\n",
    "                return np.array(c)\n",
    "            b_size = b.shape\n",
    "            if a_size[1] != b_size[0] :\n",
    "                raise ValueError(\"Can not multiply 2 matrix of dimension: \", a.shape, b.shape)\n",
    "            else:\n",
    "                c = np.zeros((a_size[0], b_size[1]), np.uint8)\n",
    "                for i in range(a_size[0]):\n",
    "                    for j in range(b_size[1]):\n",
    "                        for k in range(a_size[1]):\n",
    "                            c[i, j] =self.add(c[i, j], self.multi(a[i, k], b[k, j])) \n",
    "                return c\n",
    "\n",
    "gl = GF([4,  1, 0])\n",
    "q = gl.q\n",
    "table_str = gl.table.copy()\n",
    "table = [int(i, 2) for i in table_str]\n",
    "table = np.array(table)\n",
    "len_of_symbol = gl.len_of_symbol\n",
    "Scale = 50\n",
    "dc = 5\n",
    "q = 16\n",
    "M = int(np.log2(q))\n",
    "print(\"M:\", M)\n",
    "dtype = np.int16\n",
    "H = np.load(\"H.npy\").astype(np.int16)\n",
    "m = H.shape[0]\n",
    "n = H.shape[1]\n",
    "k = n- m\n",
    "# subindex = np.random.permutation(n)\n",
    "# H = H[:, subindex]\n",
    "H_non_zeros_index  = np.zeros((m, dc), np.uint16)\n",
    "for i in range(m):\n",
    "    stt = 0\n",
    "    for j in range(n):\n",
    "        if H[i, j]!=0:\n",
    "            H_non_zeros_index[i, stt] = j\n",
    "            stt+=1  \n",
    "Hmn = np.zeros((m, dc), np.int16)  \n",
    "for i in range(m):\n",
    "    Hmn[i]= H[i][H_non_zeros_index[i]]\n",
    "#print(Hmn)       \n",
    "\n",
    "U_Hmn = np.zeros_like(Hmn)\n",
    "for i in range(m):\n",
    "    for j in range(dc):\n",
    "        U_Hmn[i, j] = gl.reserve_e(Hmn[i, j])\n",
    "#print(U_Hmn)\n",
    "print(\"n:\", n, \"m:\", m, \"M:\", M, \"q:\", q)\n",
    "print(table_str)\n",
    "print(table)\n",
    "table_bits = np.array([np.array(list(i)).astype(np.int16) for i in table_str])\n",
    "print(table_bits)\n",
    "table_bits = cuda.to_device(table_bits)\n",
    "print(H_non_zeros_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T06:48:17.704329Z",
     "start_time": "2020-07-08T06:48:17.692993Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-eb42ca6e4af3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T12:54:39.765541Z",
     "start_time": "2020-07-07T12:54:39.649597Z"
    }
   },
   "outputs": [],
   "source": [
    "@cuda.jit(device=True)\n",
    "def add_1d(a, b, c, table):\n",
    "    for i in range(a.shape[0]):\n",
    "        c[i]=table[a[i]]^table[b[i]]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def add_1d_scalar(a, b, c, table):\n",
    "    for i in range(a.shape[0]):\n",
    "        c[i]=table[a[i]]^table[b]\n",
    "        for j in range(q):\n",
    "            if c[i]==table[j]:\n",
    "                c[i]=j\n",
    "                break\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def multi_1d_scalar(a, b, c):\n",
    "    for i in range(a.shape[0]):\n",
    "        if a[i]==0 and b ==0:\n",
    "            c[i]=1\n",
    "        else:\n",
    "            c[i]=(a[i]+b-2) % (q-1)+1\n",
    "\n",
    "@cuda.jit\n",
    "def sub_Q_permutation(sub_Q, Hmn, fix_arr0, sub_Q_permuted):\n",
    "    fix_arr =cuda.local.array(shape=(dc, 15),dtype=int16)  ################################################# sua tham so\n",
    "    for i in range(dc):\n",
    "        multi_1d_scalar(fix_arr0, Hmn[i], fix_arr[i])\n",
    "        sub_Q_permuted[0, i]=sub_Q[0, i]\n",
    "        for j in range(q-1):\n",
    "            sub_Q_permuted[fix_arr[i][j], i] = sub_Q[j+1, i]\n",
    "\n",
    "            \n",
    "@cuda.jit\n",
    "def sub_Q_selection(Q, H_index, sub_Q):\n",
    "    for  x in range(sub_Q.shape[0]):\n",
    "        for y in range(sub_Q.shape[1]):\n",
    "            sub_Q[x, y] = Q[x, H_index[y]]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def Zn(sub_Q, zn):\n",
    "    min_arr = cuda.local.array(shape=(dc),dtype=int16)\n",
    "    for i in range(dc):\n",
    "        min_arr[i] = sub_Q[0, i]\n",
    "        zn[i]=0\n",
    "        for j in range(q):\n",
    "            if min_arr[i]> sub_Q[j, i]:\n",
    "                min_arr[i]=sub_Q[j, i]\n",
    "                zn[i]=j\n",
    "                \n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def get_code(sub_Q, zn):\n",
    "    min_arr = cuda.local.array(shape=(n),dtype=int16)\n",
    "    for i in range(n):\n",
    "        min_arr[i] = sub_Q[0, i]\n",
    "        zn[i]=0\n",
    "        for j in range(q):\n",
    "            if min_arr[i]> sub_Q[j, i]:\n",
    "                min_arr[i]=sub_Q[j, i]\n",
    "                zn[i]=j\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def Delta_conversation(sub_Q, zn, fix_arr0, table, sub_Q_Delta):\n",
    "    fix_arr =cuda.local.array(shape=(dc, q),dtype=int16)\n",
    "    for i in range(dc):\n",
    "        add_1d_scalar(fix_arr0, zn[i], fix_arr[i], table)\n",
    "        for j in range(q):\n",
    "            sub_Q_Delta[fix_arr[i][j], i] = sub_Q[j, i]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def Bta(zn, B, table):\n",
    "    B[0] = zn[0]\n",
    "    for i in range(zn.shape[0]-1):\n",
    "        add_1d_scalar(B[i], zn[i+1], B[i+1], table)\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def tree_finder_1row(A, M):\n",
    "    col = cuda.local.array(shape=(1),dtype=int16)\n",
    "    value = cuda.local.array(shape=(1),dtype=int16)\n",
    "    col[0] = 0\n",
    "    value[0] = A[0]\n",
    "    for i in range(A.shape[0]):\n",
    "        if A[i]<value[0]:\n",
    "            value[0] = A[i]\n",
    "            col[0]=i\n",
    "    \n",
    "    M[0]= value[0]\n",
    "    M[1] = col[0]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def tree_finder(A, M):\n",
    "    M[0][0]= 0\n",
    "    M[0][1]=0\n",
    "    for i in range(1, q):\n",
    "        tree_finder_1row(A[i], M[i])\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def trellis_building(M, config, trellis):\n",
    "    for i in range(q):\n",
    "        trellis[i, 0] = M[i, 0]\n",
    "    for i in range(1, q):\n",
    "        for j in range(1, 1+(q-1)//2):\n",
    "            if M[config[i, j-1, 0]][1]!=M[config[i, j-1, 1]][1]:\n",
    "                trellis[i, j] = max(M[config[i, j-1, 0]][0], M[config[i, j-1, 1]][0])\n",
    "            else:\n",
    "                trellis[i, j]=10000\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def min_finder(A, min_out):\n",
    "    cols = cuda.local.array(shape=(2),dtype=int16)\n",
    "    values = cuda.local.array(shape=(2),dtype=int16)\n",
    "    if A[0]<=A[1]:\n",
    "        cols[0]=0\n",
    "        cols[1]=1\n",
    "        values[0]=A[0]\n",
    "        values[1]=A[1]\n",
    "    else:\n",
    "        cols[0]=1\n",
    "        cols[1]=0\n",
    "        values[0]=A[1]\n",
    "        values[1]=A[0]\n",
    "\n",
    "    for i in range(2, A.shape[0]):\n",
    "        if A[i]<values[0]:\n",
    "            values[1]=values[0]\n",
    "            cols[1]=cols[0]\n",
    "            values[0]=A[i]\n",
    "            cols[0]=i\n",
    "        elif A[i]>=values[0] and A[i]<values[1]:\n",
    "            values[1]=A[i]\n",
    "            cols[1]=i\n",
    "    \n",
    "    min_out[0]= values[0]\n",
    "    min_out[1] = values[1]\n",
    "    min_out[2]=cols[0]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def extra_column(trellis, M, config, extra_col):\n",
    "    for i in range(q):\n",
    "        min_out = cuda.local.array(shape=(3),dtype=int16)\n",
    "        min_finder(trellis[i], min_out)\n",
    "        extra_col[i, 0]=min_out[0]\n",
    "        extra_col[i, 1]= min_out[1]\n",
    "        if i >0:\n",
    "            if min_out[2]==0:\n",
    "                extra_col[i, 2]=extra_col[i, 3]=M[i][1]\n",
    "            else:\n",
    "                extra_col[i, 2] = M[config[i, min_out[2]-1, 0]][1]\n",
    "                extra_col[i, 3] = M[config[i, min_out[2]-1, 1]][1]\n",
    "\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def dR_computing(extra_column, dR):\n",
    "    for i in range(q):\n",
    "        for j in range(dc):\n",
    "            if extra_column[i][2]==j or extra_column[i][3]==j:\n",
    "                dR[i, j]=extra_column[i][1]\n",
    "            else:\n",
    "                dR[i, j]=extra_column[i][0]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def R_computing(dR, B, zn, R, table):\n",
    "    for i in range(q):\n",
    "        for j in range(dc):\n",
    "            index = cuda.local.array(shape=(1),dtype=int16)\n",
    "            index[0]= table[i]^table[B]^table[zn[j]]\n",
    "            for l in range(q):\n",
    "                if index[0] == table[l]:\n",
    "                    index[0]=l\n",
    "                    break\n",
    "            R[index, j]=dR[i, j]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def CN(sub_Q_permuted, zn, fix_arr0, table, config, R):\n",
    "    sub_Q_Delta = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    Delta_conversation(sub_Q_permuted, zn, fix_arr0, table, sub_Q_Delta)    \n",
    "    B = cuda.local.array(shape=(dc, 1),dtype=int16)\n",
    "    Bta(zn, B, table)\n",
    "    #B=B[-1][0]\n",
    "    M = cuda.local.array(shape=(q, 2),dtype=int16)\n",
    "    tree_finder(sub_Q_Delta, M)\n",
    "    trellis = cuda.local.array(shape=(q, 4),dtype=int16)\n",
    "    trellis_building(M, config, trellis)\n",
    "    extra_columm = cuda.local.array(shape=(q, 4),dtype=int16)\n",
    "    extra_column(trellis, M, config, extra_columm)\n",
    "    dR = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    dR_computing(extra_columm, dR)\n",
    "    R_computing(dR, B[-1][0], zn, R, table)\n",
    "#     debug(extra_columm, deg1)\n",
    "#     debug(dR, deg2)\n",
    "#     debug(trellis, deg3)\n",
    "#     debug(sub_Q_Delta, deg4)\n",
    "\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def update_sub_Q(sub_Q_permuted, R, sub_Q_updated):\n",
    "    for i in range(R.shape[0]):\n",
    "        for j in range(R.shape[1]):\n",
    "            sub_Q_updated[i][j] =  sub_Q_permuted[i][j]+R[i][j]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def subtract(Q1, Q2, Q3):\n",
    "    for i in range(Q1.shape[0]):\n",
    "        for j in range(Q1.shape[1]):\n",
    "            Q3[i][j] =  Q1[i][j]- Q2[i][j]\n",
    "\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def update_Q(Q, sub_Q_updated, H_index):\n",
    "    for i in range(Q.shape[0]):\n",
    "        for j in range(Q.shape[1]):\n",
    "            for y in range(dc):\n",
    "                if j == H_index[y]:\n",
    "                    Q[i, j]=sub_Q_updated[i, y]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def debug(X, Y):\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            Y[i, j] =X[i, j]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def Normal(sub_Q, zn, sub_Q_normaled):\n",
    "    for i in range(sub_Q.shape[0]):\n",
    "        for j in range(sub_Q.shape[1]):\n",
    "            sub_Q_normaled[i][j] =  sub_Q[i, j]-sub_Q[zn[j], j]\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def Normal2(sub_Q):\n",
    "    for i in range(sub_Q.shape[0]):\n",
    "        for j in range(sub_Q.shape[1]):\n",
    "            if sub_Q[i, j]>10000:\n",
    "                sub_Q[i, j]=10000\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def errors_computing(code_out, errors):\n",
    "    for i in range(code_out.shape[0]):\n",
    "        errors[i]=0\n",
    "        for j in range(n):\n",
    "            if code_out[i][j]!=0:\n",
    "                errors[i]+=1\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def quick_check(code, out):\n",
    "    out[0]=0\n",
    "    for i in range(code.shape[0]):\n",
    "        out[0]+=code[i]\n",
    "    \n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def Decoder(Q, Hmn, U_Hmn, H_non_zeros_index, fix_arr0, fix_arr1, table, config, code_out):\n",
    "    Rmna = cuda.local.array(shape=(m, q, dc),dtype=int16)\n",
    "    for i in range(m):\n",
    "        for j in range(q):\n",
    "            for k in range(dc):\n",
    "                Rmna[i][j][k]=0\n",
    "    sub_Q = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    sub_Q_permuted = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "\n",
    "    R = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    sub_Q_updated = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    sub_Q_unpermuted = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    zn = cuda.local.array(shape=(dc),dtype=int16)\n",
    "    sub_Q_normaled = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    check_value = cuda.local.array(shape=(1),dtype=int16)\n",
    "    for _iter in range(10):\n",
    "        for i in range(m):\n",
    "            sub_Q_selection(Q, H_non_zeros_index[i], sub_Q)\n",
    "            sub_Q_permutation(sub_Q, Hmn[i], fix_arr1, sub_Q_permuted)\n",
    "            subtract(sub_Q_permuted, Rmna[i],  sub_Q_permuted)\n",
    "            Zn(sub_Q_permuted, zn)\n",
    "            Normal(sub_Q_permuted, zn, sub_Q_normaled)\n",
    "            CN(sub_Q_normaled, zn, fix_arr0, table, config, R)\n",
    "            debug(R, Rmna[i])\n",
    "            update_sub_Q(sub_Q_normaled, R, sub_Q_updated)\n",
    "            #Normal2(sub_Q_updated)\n",
    "            sub_Q_permutation(sub_Q_updated, U_Hmn[i], fix_arr1, sub_Q_unpermuted)\n",
    "            update_Q(Q, sub_Q_unpermuted, H_non_zeros_index[i])\n",
    "        get_code(Q, code_out)\n",
    "        quick_check(code_out, check_value)\n",
    "        if check_value[0]==0:\n",
    "            break\n",
    "            \n",
    "@cuda.jit\n",
    "def S_Decoder(Q, Hmn, U_Hmn, H_non_zeros_index, fix_arr0, fix_arr1, table, config, code_out):\n",
    "    Rmna = cuda.local.array(shape=(m, q, dc),dtype=int16)\n",
    "    for i in range(m):\n",
    "        for j in range(q):\n",
    "            for k in range(dc):\n",
    "                Rmna[i][j][k]=0\n",
    "    sub_Q = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    sub_Q_permuted = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "\n",
    "    R = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    sub_Q_updated = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    sub_Q_unpermuted = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    zn = cuda.local.array(shape=(dc),dtype=int16)\n",
    "    sub_Q_normaled = cuda.local.array(shape=(q, dc),dtype=int16)\n",
    "    check_value = cuda.local.array(shape=(1),dtype=int16)\n",
    "    for _iter in range(10):\n",
    "        for i in range(m):\n",
    "            sub_Q_selection(Q, H_non_zeros_index[i], sub_Q)\n",
    "            sub_Q_permutation(sub_Q, Hmn[i], fix_arr1, sub_Q_permuted)\n",
    "            subtract(sub_Q_permuted, Rmna[i],  sub_Q_permuted)\n",
    "            Zn(sub_Q_permuted, zn)\n",
    "            Normal(sub_Q_permuted, zn, sub_Q_normaled)\n",
    "            CN(sub_Q_normaled, zn, fix_arr0, table, config, R)\n",
    "            debug(R, Rmna[i])\n",
    "            update_sub_Q(sub_Q_normaled, R, sub_Q_updated)\n",
    "            #Normal2(sub_Q_updated)\n",
    "            sub_Q_permutation(sub_Q_updated, U_Hmn[i], fix_arr1, sub_Q_unpermuted)\n",
    "            update_Q(Q, sub_Q_unpermuted, H_non_zeros_index[i])\n",
    "        get_code(Q, code_out)\n",
    "        quick_check(code_out, check_value)\n",
    "        if check_value[0]==0:\n",
    "            break\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def multi_Decoder(Q, Hmn, U_Hmn, H_non_zeros_index, fix_arr0, fix_arr1, table, config, code_out, errors):\n",
    "    i = cuda.grid(1)\n",
    "    if i < Q.shape[0]:\n",
    "        Decoder(Q[i], Hmn, U_Hmn, H_non_zeros_index, fix_arr0, fix_arr1, table, config, code_out[i])\n",
    "    errors_computing(code_out, errors)\n",
    "    \n",
    "\n",
    "lop10e = np.log10(np.e)\n",
    "@cuda.jit\n",
    "def log10(A, B, C):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < A.shape[0] and j < A.shape[1]:\n",
    "        B[i][j]= lop10e*math.log(A[i][j])\n",
    "        if B[i][j]>3:\n",
    "            B[i][j]=3\n",
    "        C[j][i] = int(B[i][j]*100)\n",
    "\n",
    "@cuda.jit\n",
    "def probBits(bits, probBs, N0):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i <bits.shape[0] and j < bits.shape[1]:\n",
    "        d1 = abs(-1-bits[i][j])\n",
    "        d2 = abs(1-bits[i][j])\n",
    "        p0 = np.e**(-d1/N0)/(np.e**(-d1/N0)+np.e**(-d2/N0))\n",
    "        p1 = 1-p0\n",
    "        probBs[i][j][0] = p0\n",
    "        probBs[i][j][1] = p1\n",
    "\n",
    "@cuda.jit\n",
    "def probS(probBs, table_bits, Q_out):\n",
    "    i = cuda.grid(1)\n",
    "    if i <probBs.shape[0]:\n",
    "        p_max = 0\n",
    "        for j in range(q):\n",
    "            Q_out[i][j]=1\n",
    "            for k in range(M):\n",
    "                Q_out[i][j]*=probBs[i][k][table_bits[j][k]]\n",
    "            if Q_out[i][j] >  p_max:\n",
    "                p_max = Q_out[i][j]\n",
    "        for j in range(q):\n",
    "            Q_out[i][j] = p_max/Q_out[i][j]\n",
    "        \n",
    "\n",
    "@cuda.jit\n",
    "def S2B(message, table_bits, bits_out):\n",
    "    for i in range(message.shape[0]):\n",
    "        for j in range(M):\n",
    "            bits_out[i, j]= table_bits[message[i]][j]\n",
    "\n",
    "@cuda.jit\n",
    "def rand_array(rng_states, N0, out):\n",
    "    thread_id = cuda.grid(1)\n",
    "    x = xoroshiro128p_normal_float32(rng_states, thread_id)\n",
    "    out[thread_id] = x\n",
    "    out[thread_id] = out[thread_id]*N0\n",
    "    out[thread_id] = out[thread_id]-1\n",
    "    \n",
    "@cuda.jit\n",
    "def hsplit(A, B):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i<A.shape[0] and j < A.shape[1]:\n",
    "        B[j//n][i][j%n]=A[i][j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T12:46:18.318562Z",
     "start_time": "2020-07-07T12:46:17.480939Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "config = cuda.to_device(np.load(\"config.npy\"))\n",
    "fix_arr0 = cuda.to_device(np.arange(q))\n",
    "fix_arr1 = cuda.to_device(np.arange(q))[1:]\n",
    "U_Hmn = cuda.to_device(U_Hmn)\n",
    "Hmn = cuda.to_device(Hmn)\n",
    "H_non_zeros_index = cuda.to_device(H_non_zeros_index)\n",
    "table = cuda.to_device(table)\n",
    "zn = cuda.to_device(np.zeros(dc, np.int16))\n",
    "code_out = cuda.to_device(np.zeros((batch_size, n), np.int16))\n",
    "errors = np.zeros(batch_size, np.int16)\n",
    "threads_per_block_rd = 128\n",
    "blocks_rd = (n*M*batch_size+threads_per_block_rd-1)//threads_per_block_rd\n",
    "rng_states = create_xoroshiro128p_states(threads_per_block_rd * blocks_rd, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T12:46:19.217994Z",
     "start_time": "2020-07-07T12:46:19.126133Z"
    }
   },
   "outputs": [],
   "source": [
    "cf.A0 = cuda.to_device(np.zeros((batch_size*M*n), dtype=np.float32))\n",
    "cf.A = cuda.to_device(np.zeros((batch_size*n , M), dtype=np.float32))\n",
    "cf.B = cuda.to_device(np.zeros((batch_size*n, M, 2)))\n",
    "cf.C = cuda.to_device(np.zeros((batch_size*n, q)))\n",
    "cf.C2 = cuda.to_device(np.zeros((batch_size*n, q)))\n",
    "cf.C3 = cuda.to_device(np.zeros((q, batch_size*n), np.int16))\n",
    "cf.out = cuda.to_device(np.zeros((batch_size, q, n), np.int16))\n",
    "def BPSK(sample, SNRdB):\n",
    "    Eb = 1\n",
    "    N0 = Eb/10**(SNRdB/10)\n",
    "    sigma = np.sqrt(N0/2)\n",
    "    #print(N0, sigma)\n",
    "    rand_array[blocks_rd, threads_per_block_rd](rng_states, sigma, cf.A0)\n",
    "    cf.A = cf.A0.reshape((batch_size*n, M))\n",
    "    thread_probBits = (128, 8)\n",
    "    block_probBits = ((cf.A.shape[0]+thread_probBits[0]-1)//thread_probBits[0], (cf.A.shape[1]+thread_probBits[1]-1)//thread_probBits[1])\n",
    "    probBits[block_probBits, thread_probBits](cf.A, cf.B, N0)\n",
    "    thread_probS = 128\n",
    "    block_probS = (cf.B.shape[0]+thread_probS-1)//thread_probS\n",
    "    probS[block_probS, thread_probS](cf.B, table_bits, cf.C)\n",
    "    thread_log10 = (128, 8)\n",
    "    block_log10 = ((cf.C.shape[0]+thread_log10[0]-1)//thread_log10[0], (cf.C.shape[1]+thread_log10[1]-1)//thread_log10[1])\n",
    "    log10[thread_log10, block_log10](cf.C, cf.C2, cf.C3)\n",
    "    thread_hsplit = (8, 128)\n",
    "    block_hsplit = ((cf.C3.shape[0]+thread_hsplit[0]-1)//thread_hsplit[0], (cf.C3.shape[1]+thread_hsplit[1]-1)//thread_hsplit[1])\n",
    "    hsplit[block_hsplit, thread_hsplit](cf.C3, cf.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T12:41:14.197219Z",
     "start_time": "2020-07-07T12:41:14.183013Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test BPSK\n",
    "BPSK(batch_size, 1)\n",
    "_Q = cf.out.copy_to_host()[0]\n",
    "print(_Q)\n",
    "print(_Q[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T12:52:37.109513Z",
     "start_time": "2020-07-07T12:52:37.101940Z"
    }
   },
   "outputs": [],
   "source": [
    "Qi = np.load(\"Qi.npy\")\n",
    "print(Qi[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T12:55:22.600268Z",
     "start_time": "2020-07-07T12:55:22.588581Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_Q = np.zeros((q, dc), np.int16)\n",
    "sub_Q_pernuted = np.zeros((q, dc), np.int16)\n",
    "sub_Q_selection[1, 8](Qi, H_non_zeros_index[0], sub_Q)\n",
    "print(sub_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T12:41:23.026625Z",
     "start_time": "2020-07-07T12:41:23.020161Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(SNRdB, batch_size):\n",
    "    eb = 0\n",
    "    ef = 0\n",
    "    samples = 0\n",
    "    step = int(1e9//batch_size)\n",
    "    for i in tnrange(step):\n",
    "        BPSK(batch_size, SNRdB)\n",
    "        multi_Decoder[4, batch_size//4](cf.out, Hmn, U_Hmn, H_non_zeros_index, fix_arr0, fix_arr1, table, config, code_out, errors) \n",
    "        eb+=np.sum(errors)\n",
    "        for i in range(batch_size):\n",
    "            if errors[i]!=0:\n",
    "                ef+=1\n",
    "        samples +=batch_size\n",
    "        if ef>200:\n",
    "            break\n",
    "    print(SNRdB, samples, ef, eb, np.log10(ef/ samples), np.log10(eb/ (samples*n)))\n",
    "    return samples, ef, eb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T12:41:35.222912Z",
     "start_time": "2020-07-07T12:41:26.910356Z"
    }
   },
   "outputs": [],
   "source": [
    "SNRdB_arr = (0,  1, 2, 3, 4, 4.5, 5, 5.5, 5.8, 6, 6.2)\n",
    "ef_arr = []\n",
    "es_arr = []\n",
    "S = []\n",
    "for i in range(len(SNRdB_arr)):\n",
    "    s, ef, es = test(SNRdB_arr[i], batch_size)\n",
    "    S.append(s)\n",
    "    ef_arr.append(ef)\n",
    "    es_arr.append(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T00:15:51.056657Z",
     "start_time": "2020-06-09T00:15:50.224860Z"
    }
   },
   "outputs": [],
   "source": [
    "N = len(S)\n",
    "SER = [es_arr[i]/(S[i]*n) for i in range(N)]\n",
    "FER = [ef_arr[i]/(S[i]) for i in range(N)]\n",
    "import  matplotlib.pyplot as plt \n",
    "fig = plt.figure(figsize=(7,6))\n",
    "# plt.plot(SNRdB1, BER_BPSK, label='B-PSK', linewidth=4.0)\n",
    "plt.plot(SNRdB_arr[:N], SER,'-', label='SER-LDPC-GF(8)-Iter-10', linewidth=4.0)\n",
    "plt.plot(SNRdB_arr[:N], FER,'-', label='FER-LDPC-GF(8)-Iter-10', linewidth=4.0)\n",
    "plt.xticks(np.arange(0, 8, 1))\n",
    "plt.yscale('log')\n",
    "plt.ylabel('log10')\n",
    "plt.xlabel('SNR(dB)')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "# plt.savefig('Ber.png')\n",
    "# plt.close(fig)  \n",
    "plt.show()\n",
    "print(ef_arr)\n",
    "print(es_arr)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-09T01:15:29.137Z"
    }
   },
   "outputs": [],
   "source": [
    "[612, 257, 204, 204, 201, 201, 201, 201, 201, 201, 201]\n",
    "[3973, 1308, 823, 657, 610, 517, 495, 472, 506, 503, 477]\n",
    "[2048, 4096, 22528, 235520, 2279424, 6526976, 20772864, 73396224, 192505856, 344094720, 676468736]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-03T01:12:37.564825Z",
     "start_time": "2020-07-03T01:12:37.418196Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_de_lai)",
   "language": "python",
   "name": "conda_de_lai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
